{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://huggingface.co/docs/transformers/en/model_doc/llava\n",
    "\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-1.5-7b-hf\",\n",
    "    torch_dtype=torch.bfloat16 # torch.float16 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"philschmid/amazon-product-descriptions-vlm\"\n",
    "dataset = load_dataset(dataset_id, split=\"train\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display an example from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def display_example(example):\n",
    "    print(f\"Product Name: {example['Product Name']}\")\n",
    "    print(f\"Category: {example['Category']}\")\n",
    "    print(f\"Description: {example['description']}\")\n",
    "    print(\"image:\")\n",
    "    \n",
    "    # Convert bytes to PIL Image\n",
    "    image = example['image']\n",
    "\n",
    "    # Display using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Display an example\n",
    "display_example(dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the dataset for the TRL trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  you need to convert the dataset format to the the TRL trainer \n",
    "#  https://huggingface.co/docs/trl/en/sft_trainer\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "##PRODUCT NAME##: {product_name}\n",
    "##CATEGORY##: {category}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_data(sample):\n",
    "    return {    \n",
    "        \"images\": [sample[\"image\"]],\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"Create a Short Product description based on the provided ##PRODUCT NAME## and ##CATEGORY## and image. Only return description. The description should be SEO optimized and for a better mobile search experience.\"}],\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{'type': 'image', \"text\": None },\n",
    "                        {\"type\": \"text\", \"text\": prompt.format(product_name=sample[\"Product Name\"], category=sample[\"Category\"])}\n",
    "                        ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": sample[\"description\"]}],\n",
    "        },\n",
    "    ]\n",
    "    }\n",
    "\n",
    "\n",
    "train_valid = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_valid[\"train\"]\n",
    "valid_dataset = train_valid[\"test\"]\n",
    "\n",
    "\n",
    "formatted_train_ds = [format_data(sample) for sample in train_dataset]\n",
    "formatted_val_ds = [format_data(sample) for sample in valid_dataset]\n",
    "print(formatted_train_ds[0])\n",
    "print(formatted_val_ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a data collator to encode text and image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataCollator:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "    ################\n",
    "    # Create a data collator to encode text and image pairs\n",
    "    ################\n",
    "    def __call__(self, examples):\n",
    "        texts = []\n",
    "        images = []\n",
    "        for example in examples:\n",
    "            messages = example[\"messages\"]\n",
    "            text = self.processor.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=False\n",
    "            )\n",
    "            texts.append(text)\n",
    "            images.append(example[\"images\"][0])\n",
    "\n",
    "        batch = self.processor(texts, images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # The labels are the input_ids, and we mask the padding tokens in the loss computation\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        if self.processor.tokenizer.pad_token_id is not None:\n",
    "            labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "    \n",
    "\n",
    "data_collator = DataCollator(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(processor.apply_chat_template(formatted_train_ds[0][\"messages\"], tokenize=False, add_generation_prompt=False))\n",
    "print(data_collator([formatted_train_ds[0]]))\n",
    "print(data_collator([formatted_val_ds[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import (\n",
    "    ModelConfig,\n",
    "    SFTConfig,\n",
    "    SFTTrainer,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"llava-1.5-7b-hf-philschmid-amazon-product-descriptions-vlm\",\n",
    "    learning_rate= 2e-4,\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=2,\n",
    "    max_seq_length=1024,\n",
    "    dataset_text_field=\"text\",  # need a dummy field\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    fp16=False, # make sure this is consistant with the model loading and data loading with torch.float16\n",
    "    bf16=True, # make sure this is consistant with the model loading and data loading with torch.bfloat16\n",
    "    tf32=True,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=formatted_train_ds,\n",
    "    eval_dataset=formatted_val_ds,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafactory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
